{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "log_data = [] \n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "azure_oai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_oai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_version = \"2024-02-15-preview\"\n",
    "llm_name = \"gpt-4o\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "llm=AzureOpenAI(deployment_name=\"gpt-4o\", model=\"gpt-4o\", temperature=0, api_key=azure_oai_key, azure_endpoint=azure_oai_endpoint, api_version=api_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "from docx import Document\n",
    "import PyPDF2\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import streamlit as st\n",
    "\n",
    "# Dosya yükleyici bileşen\n",
    "uploaded_files = st.file_uploader(\"Upload your documents (for now it only works with files that have .txt, .pdf or .docx extension):\", \n",
    "                                  accept_multiple_files=True, key=\"file_uploader\")\n",
    "\n",
    "# Yüklenen dosyaları Document formatında okuyarak işleme\n",
    "documents = []\n",
    "\n",
    "for file in uploaded_files:\n",
    "    file_name = file.name\n",
    "    file_extension = os.path.splitext(file_name)[1].lower()\n",
    "\n",
    "    if file_extension == '.txt':\n",
    "        text_loader = TextLoader(file)\n",
    "        documents.extend(text_loader.load())\n",
    "    elif file_extension == '.pdf':\n",
    "        pdf_loader = PyPDFLoader(io.BytesIO(file.read()))\n",
    "        documents.extend(pdf_loader.load())\n",
    "    elif file_extension == '.docx':\n",
    "        docx_loader = Document(io.BytesIO(file.read()))\n",
    "        documents.extend(docx_loader.load())\n",
    "\n",
    "# Metinleri parçalara ayırma\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The name of the file that the chunk is from.\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page from the file that the chunk is from.\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "# metadata_field_info = [\n",
    "#     AttributeInfo(\n",
    "#         name=\"source\",\n",
    "#         description=\"The lecture the chunk is from, should be one of `docs/cs229_lectures/MachineLearning-Lecture01.pdf`, `docs/cs229_lectures/MachineLearning-Lecture02.pdf`, or `docs/cs229_lectures/MachineLearning-Lecture03.pdf`\",\n",
    "#         type=\"string\",\n",
    "#     ),\n",
    "#     AttributeInfo(\n",
    "#         name=\"page\",\n",
    "#         description=\"The page from the lecture\",\n",
    "#         type=\"integer\",\n",
    "#     ),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content_description = \"Lecture notes\"\n",
    "\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectordb,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# document_content_description = \"Lecture notes\"\n",
    "# llm = OpenAI(model='gpt-3.5-turbo-instruct', temperature=0)\n",
    "# retriever = SelfQueryRetriever.from_llm(\n",
    "#     llm,\n",
    "#     vectordb,\n",
    "#     document_content_description,\n",
    "#     metadata_field_info,\n",
    "#     verbose=True\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
