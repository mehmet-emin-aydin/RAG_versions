{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.text_splitter import CodeSplitter\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.packs.code_hierarchy import CodeHierarchyNodeParser\n",
    "from llama_index.packs.code_hierarchy import CodeHierarchyAgentPack\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "def print_python(python_text):\n",
    "    \"\"\"This function prints python text in ipynb nicely formatted.\"\"\"\n",
    "    display(Markdown(\"```python\\n\" + python_text + \"```\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "log_data = [] \n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "azure_oai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_oai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_version = \"2024-02-15-preview\"\n",
    "llm_name = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"LLM Compiler Output Parser.\"\"\"\n",
      "\n",
      "import re\n",
      "from typing import Any, Dict, List, Sequence\n",
      "\n",
      "from llama_index.core.tools import BaseTool\n",
      "from llama_index.core.types import BaseOutputParser\n",
      "\n",
      "from .schema import JoinerOutput, LLMCompilerParseResult\n",
      "from .utils import get_graph_dict\n",
      "\n",
      "THOUGHT_PATTERN = r\"Thought: ([^\\n]*)\"\n",
      "ACTION_PATTERN = r\"\\n*(\\d+)\\. (\\w+)\\((.*)\\)(\\s*#\\w+\\n)?\"\n",
      "# $1 or ${1} -> 1\n",
      "ID_PATTERN = r\"\\$\\{?(\\d+)\\}?\"\n",
      "\n",
      "END_OF_PLAN = \"<END_OF_PLAN>\"\n",
      "JOINER_REPLAN = \"Replan\"\n",
      "\n",
      "\n",
      "def default_dependency_rule(idx: int, args: str) -> bool:\n",
      "    # Code replaced for brevity. See node_id 695dfe4a-3393-48d6-b5f0-41d5f72306ff\n",
      "\n",
      "\n",
      "class LLMCompilerPlanParser(BaseOutputParser):\n",
      "    # Code replaced for brevity. See node_id ffb20a71-9e35-4be8-a07d-b512b75c350d\n",
      "\n",
      "\n",
      "### Helper functions\n",
      "\n",
      "\n",
      "class LLMCompilerJoinerParser(BaseOutputParser):\n",
      "    # Code replaced for brevity. See node_id cb077b67-dc0a-4f3d-99b1-6c5959f6ef3e\n",
      "****************************************************************************************************\n",
      "def default_dependency_rule(idx: int, args: str) -> bool:\n",
      "    \"\"\"Default dependency rule.\"\"\"\n",
      "    matches = re.findall(ID_PATTERN, args)\n",
      "    numbers = [int(match) for match in matches]\n",
      "    return idx in numbers\n",
      "****************************************************************************************************\n",
      "class LLMCompilerPlanParser(BaseOutputParser):\n",
      "    \"\"\"LLM Compiler plan output parser.\n",
      "\n",
      "    Directly adapted from source code: https://github.com/SqueezeAILab/LLMCompiler/blob/main/src/llm_compiler/output_parser.py.\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, tools: Sequence[BaseTool]):\n",
      "        # Code replaced for brevity. See node_id 48203786-3bc6-49fe-b5c9-07e03f8bfc05\n",
      "\n",
      "    def parse(self, text: str) -> Dict[int, Any]:\n",
      "        # 1. search(\"Ronaldo number of kids\") -> 1, \"search\", '\"Ronaldo number of kids\"'\n",
      "        # pattern = r\"(\\d+)\\. (\\w+)\\(([^)]+)\\)\"\n",
      "        # Code replaced for brevity. See node_id 462cec4d-fffa-48aa-9f63-16ab5a8fa236\n",
      "****************************************************************************************************\n",
      "def __init__(self, tools: Sequence[BaseTool]):\n",
      "        \"\"\"Init params.\"\"\"\n",
      "        self.tools = tools\n",
      "****************************************************************************************************\n",
      "def parse(self, text: str) -> Dict[int, Any]:\n",
      "        # 1. search(\"Ronaldo number of kids\") -> 1, \"search\", '\"Ronaldo number of kids\"'\n",
      "        # pattern = r\"(\\d+)\\. (\\w+)\\(([^)]+)\\)\"\n",
      "        pattern = rf\"(?:{THOUGHT_PATTERN}\\n)?{ACTION_PATTERN}\"\n",
      "        matches = re.findall(pattern, text)\n",
      "\n",
      "        # convert matches to a list of LLMCompilerParseResult\n",
      "        results: List[LLMCompilerParseResult] = []\n",
      "        for match in matches:\n",
      "            thought, idx, tool_name, args, _ = match\n",
      "            idx = int(idx)\n",
      "            results.append(\n",
      "                LLMCompilerParseResult(\n",
      "                    thought=thought, idx=idx, tool_name=tool_name, args=args\n",
      "                )\n",
      "            )\n",
      "\n",
      "        # get graph dict\n",
      "        return get_graph_dict(results, self.tools)\n",
      "****************************************************************************************************\n",
      "class LLMCompilerJoinerParser(BaseOutputParser):\n",
      "    \"\"\"LLM Compiler output parser for the join step.\n",
      "\n",
      "    Adapted from _parse_joiner_output in\n",
      "    https://github.com/SqueezeAILab/LLMCompiler/blob/main/src/llm_compiler/llm_compiler.py\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    def parse(self, text: str) -> JoinerOutput:\n",
      "        # Code replaced for brevity. See node_id 321ba4b5-bb7c-4c88-afeb-e866fd9df9ae\n",
      "****************************************************************************************************\n",
      "def parse(self, text: str) -> JoinerOutput:\n",
      "        \"\"\"Parse.\"\"\"\n",
      "        thought, answer, is_replan = \"\", \"\", False  # default values\n",
      "        raw_answers = text.split(\"\\n\")\n",
      "        for answer in raw_answers:\n",
      "            if answer.startswith(\"Action:\"):\n",
      "                answer = answer[answer.find(\"(\") + 1 : answer.find(\")\")]\n",
      "                is_replan = JOINER_REPLAN in answer\n",
      "            elif answer.startswith(\"Thought:\"):\n",
      "                thought = answer.split(\"Thought:\")[1].strip()\n",
      "        return JoinerOutput(thought=thought, answer=answer, is_replan=is_replan)\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "llm=AzureOpenAI(deployment_name=\"gpt-4o\", model=\"gpt-4o\", temperature=0, api_key=azure_oai_key, azure_endpoint=azure_oai_endpoint, api_version=api_version)\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=['../output_parser.py'],\n",
    "    file_metadata=lambda x: {\"filepath\": x},\n",
    ").load_data()\n",
    "\n",
    "split_nodes = CodeHierarchyNodeParser(\n",
    "    language=\"python\",\n",
    "    # You can further parameterize the CodeSplitter to split the code\n",
    "    # into \"chunks\" that match your context window size using\n",
    "    # chunck_lines and max_chars parameters, here we just use the defaults\n",
    "    code_splitter=CodeSplitter(language=\"python\", max_chars=1000, chunk_lines=10, ),\n",
    ").get_nodes_from_documents(documents)\n",
    "for node in split_nodes:\n",
    "    print(node.text , end=\"\\n{delimeter}\\n\".format(delimeter=\"*\"*100))  \n",
    "pack = CodeHierarchyAgentPack(split_nodes=split_nodes, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: How does the parse function from the llm compiler plan parser work? Provide specific implementation details.\n",
      "=== Calling Function ===\n",
      "Calling function: code_search with args: {\"input\":\"LLMCompilerPlanParser parse\"}\n",
      "Got output: None\n",
      "========================\n",
      "\n",
      "=== Calling Function ===\n",
      "Calling function: code_search with args: {\"input\":\"LLMCompilerPlanParser\"}\n",
      "Got output: class LLMCompilerPlanParser(BaseOutputParser):\n",
      "    \"\"\"LLM Compiler plan output parser.\n",
      "\n",
      "    Directly adapted from source code: https://github.com/SqueezeAILab/LLMCompiler/blob/main/src/llm_compiler/output_parser.py.\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, tools: Sequence[BaseTool]):\n",
      "        # Code replaced for brevity. See node_id 48203786-3bc6-49fe-b5c9-07e03f8bfc05\n",
      "\n",
      "    def parse(self, text: str) -> Dict[int, Any]:\n",
      "        # 1. search(\"Ronaldo number of kids\") -> 1, \"search\", '\"Ronaldo number of kids\"'\n",
      "        # pattern = r\"(\\d+)\\. (\\w+)\\(([^)]+)\\)\"\n",
      "        # Code replaced for brevity. See node_id 462cec4d-fffa-48aa-9f63-16ab5a8fa236\n",
      "========================\n",
      "\n",
      "=== Calling Function ===\n",
      "Calling function: code_search with args: {\"input\":\"462cec4d-fffa-48aa-9f63-16ab5a8fa236\"}\n",
      "Got output: def parse(self, text: str) -> Dict[int, Any]:\n",
      "        # 1. search(\"Ronaldo number of kids\") -> 1, \"search\", '\"Ronaldo number of kids\"'\n",
      "        # pattern = r\"(\\d+)\\. (\\w+)\\(([^)]+)\\)\"\n",
      "        pattern = rf\"(?:{THOUGHT_PATTERN}\\n)?{ACTION_PATTERN}\"\n",
      "        matches = re.findall(pattern, text)\n",
      "\n",
      "        # convert matches to a list of LLMCompilerParseResult\n",
      "        results: List[LLMCompilerParseResult] = []\n",
      "        for match in matches:\n",
      "            thought, idx, tool_name, args, _ = match\n",
      "            idx = int(idx)\n",
      "            results.append(\n",
      "                LLMCompilerParseResult(\n",
      "                    thought=thought, idx=idx, tool_name=tool_name, args=args\n",
      "                )\n",
      "            )\n",
      "\n",
      "        # get graph dict\n",
      "        return get_graph_dict(results, self.tools)\n",
      "========================\n",
      "\n",
      "The `parse` function in the `LLMCompilerPlanParser` class is designed to process a given text and extract structured information from it. Here are the specific implementation details:\n",
      "\n",
      "1. **Pattern Matching**:\n",
      "   - The function uses a regular expression pattern to find matches in the input text. The pattern is defined as:\n",
      "     ```python\n",
      "     pattern = rf\"(?:{THOUGHT_PATTERN}\\n)?{ACTION_PATTERN}\"\n",
      "     ```\n",
      "   - This pattern is designed to capture specific parts of the text that match the defined `THOUGHT_PATTERN` and `ACTION_PATTERN`.\n",
      "\n",
      "2. **Finding Matches**:\n",
      "   - The `re.findall` function is used to find all occurrences in the text that match the pattern:\n",
      "     ```python\n",
      "     matches = re.findall(pattern, text)\n",
      "     ```\n",
      "\n",
      "3. **Processing Matches**:\n",
      "   - The function initializes an empty list `results` to store the parsed results:\n",
      "     ```python\n",
      "     results: List[LLMCompilerParseResult] = []\n",
      "     ```\n",
      "   - It then iterates over each match found:\n",
      "     ```python\n",
      "     for match in matches:\n",
      "         thought, idx, tool_name, args, _ = match\n",
      "         idx = int(idx)\n",
      "         results.append(\n",
      "             LLMCompilerParseResult(\n",
      "                 thought=thought, idx=idx, tool_name=tool_name, args=args\n",
      "             )\n",
      "         )\n",
      "     ```\n",
      "   - For each match, it extracts the `thought`, `idx`, `tool_name`, and `args` components, converts `idx` to an integer, and appends a new `LLMCompilerParseResult` object to the `results` list.\n",
      "\n",
      "4. **Generating Graph Dictionary**:\n",
      "   - Finally, the function returns a graph dictionary created from the parsed results and the tools provided during initialization:\n",
      "     ```python\n",
      "     return get_graph_dict(results, self.tools)\n",
      "     ```\n",
      "\n",
      "In summary, the `parse` function takes a text input, uses regular expressions to extract structured information, processes the matches to create a list of `LLMCompilerParseResult` objects, and then generates a graph dictionary from these results.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    pack.run(\n",
    "        \"How does the parse function from the llm compiler plan parser work? Provide specific implementation details.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
