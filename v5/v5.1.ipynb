{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.text_splitter import CodeSplitter\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.packs.code_hierarchy import CodeHierarchyNodeParser\n",
    "from llama_index.packs.code_hierarchy import CodeHierarchyAgentPack\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "def print_python(python_text):\n",
    "    \"\"\"This function prints python text in ipynb nicely formatted.\"\"\"\n",
    "    display(Markdown(\"```python\\n\" + python_text + \"```\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "log_data = [] \n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "azure_oai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_oai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_version = \"2024-02-15-preview\"\n",
    "llm_name = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "llm=AzureOpenAI(deployment_name=\"gpt-4o\", model=\"gpt-4o\", temperature=0, api_key=azure_oai_key, azure_endpoint=azure_oai_endpoint, api_version=api_version)\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=['../output_parser.py'],\n",
    "    file_metadata=lambda x: {\"filepath\": x},\n",
    ").load_data()\n",
    "\n",
    "split_nodes = CodeHierarchyNodeParser(\n",
    "    language=\"python\",\n",
    "    # You can further parameterize the CodeSplitter to split the code\n",
    "    # into \"chunks\" that match your context window size using\n",
    "    # chunck_lines and max_chars parameters, here we just use the defaults\n",
    "    code_splitter=CodeSplitter(language=\"python\", max_chars=1000, chunk_lines=10, ),\n",
    ").get_nodes_from_documents(documents)\n",
    "for node in split_nodes:\n",
    "    print(node.text , end=\"\\n**************************\\n\")\n",
    "pack = CodeHierarchyAgentPack(split_nodes=split_nodes, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: How does the parse function from the llm compiler plan parser work? Provide specific implementation details.\n",
      "=== Calling Function ===\n",
      "Calling function: code_search with args: {\"input\":\"LLMCompilerPlanParser parse\"}\n",
      "Got output: None\n",
      "========================\n",
      "\n",
      "=== Calling Function ===\n",
      "Calling function: code_search with args: {\"input\":\"LLMCompilerPlanParser\"}\n",
      "Got output: class LLMCompilerPlanParser(BaseOutputParser):\n",
      "    \"\"\"LLM Compiler plan output parser.\n",
      "\n",
      "    Directly adapted from source code: https://github.com/SqueezeAILab/LLMCompiler/blob/main/src/llm_compiler/output_parser.py.\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, tools: Sequence[BaseTool]):\n",
      "        # Code replaced for brevity. See node_id ff0d516e-5f75-418a-abcd-5c456f23bf24\n",
      "\n",
      "    def parse(self, text: str) -> Dict[int, Any]:\n",
      "        # 1. search(\"Ronaldo number of kids\") -> 1, \"search\", '\"Ronaldo number of kids\"'\n",
      "        # pattern = r\"(\\d+)\\. (\\w+)\\(([^)]+)\\)\"\n",
      "        # Code replaced for brevity. See node_id 3e431bd5-2dbc-4078-86e5-45e194e291f9\n",
      "========================\n",
      "\n",
      "=== Calling Function ===\n",
      "Calling function: code_search with args: {\"input\":\"3e431bd5-2dbc-4078-86e5-45e194e291f9\"}\n",
      "Got output: def parse(self, text: str) -> Dict[int, Any]:\n",
      "        # 1. search(\"Ronaldo number of kids\") -> 1, \"search\", '\"Ronaldo number of kids\"'\n",
      "        # pattern = r\"(\\d+)\\. (\\w+)\\(([^)]+)\\)\"\n",
      "        pattern = rf\"(?:{THOUGHT_PATTERN}\\n)?{ACTION_PATTERN}\"\n",
      "        matches = re.findall(pattern, text)\n",
      "\n",
      "        # convert matches to a list of LLMCompilerParseResult\n",
      "        results: List[LLMCompilerParseResult] = []\n",
      "        for match in matches:\n",
      "            thought, idx, tool_name, args, _ = match\n",
      "            idx = int(idx)\n",
      "            results.append(\n",
      "                LLMCompilerParseResult(\n",
      "                    thought=thought, idx=idx, tool_name=tool_name, args=args\n",
      "                )\n",
      "            )\n",
      "\n",
      "        # get graph dict\n",
      "        return get_graph_dict(results, self.tools)\n",
      "========================\n",
      "\n",
      "The `parse` function in the `LLMCompilerPlanParser` class is designed to parse a given text and extract structured information from it. Here are the specific implementation details:\n",
      "\n",
      "1. **Pattern Matching**:\n",
      "   - The function uses a regular expression pattern to find matches in the input text. The pattern is defined as:\n",
      "     ```python\n",
      "     pattern = rf\"(?:{THOUGHT_PATTERN}\\n)?{ACTION_PATTERN}\"\n",
      "     ```\n",
      "   - This pattern is designed to match specific structures in the text, which include thoughts and actions.\n",
      "\n",
      "2. **Finding Matches**:\n",
      "   - The `re.findall` function is used to find all occurrences of the pattern in the input text:\n",
      "     ```python\n",
      "     matches = re.findall(pattern, text)\n",
      "     ```\n",
      "\n",
      "3. **Processing Matches**:\n",
      "   - The function initializes an empty list to store the results:\n",
      "     ```python\n",
      "     results: List[LLMCompilerParseResult] = []\n",
      "     ```\n",
      "   - It then iterates over the matches and processes each one:\n",
      "     ```python\n",
      "     for match in matches:\n",
      "         thought, idx, tool_name, args, _ = match\n",
      "         idx = int(idx)\n",
      "         results.append(\n",
      "             LLMCompilerParseResult(\n",
      "                 thought=thought, idx=idx, tool_name=tool_name, args=args\n",
      "             )\n",
      "         )\n",
      "     ```\n",
      "   - Each match is unpacked into its components: `thought`, `idx`, `tool_name`, `args`, and an unused variable `_`.\n",
      "   - The `idx` is converted to an integer.\n",
      "   - A new `LLMCompilerParseResult` object is created with the extracted components and added to the `results` list.\n",
      "\n",
      "4. **Generating the Graph Dictionary**:\n",
      "   - Finally, the function generates a graph dictionary from the results and the tools provided during initialization:\n",
      "     ```python\n",
      "     return get_graph_dict(results, self.tools)\n",
      "     ```\n",
      "\n",
      "In summary, the `parse` function uses regular expressions to extract structured information from the input text, processes the matches to create `LLMCompilerParseResult` objects, and then generates a graph dictionary from these results.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    pack.run(\n",
    "        \"How does the parse function from the llm compiler plan parser work? Provide specific implementation details.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
